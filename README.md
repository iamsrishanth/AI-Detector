<div align="center">

# ğŸ›¡ï¸ AI Detector

**Unified AI-generated content detection for images, videos, and deepfake audio.**

[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.5+-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org/)
[![Gradio](https://img.shields.io/badge/Gradio-Web_UI-F97316?style=for-the-badge&logo=gradio&logoColor=white)](https://gradio.app/)
[![License](https://img.shields.io/badge/License-Apache_2.0-blue?style=for-the-badge)](LICENSE)

<p>
  A powerful, modular Python toolkit that combines <b>image/video AI detection</b> (CLIP & ViT) and <b>audio deepfake detection</b> (spectral analysis & RandomForest) into one unified CLI and web interface.
</p>

---

</div>

> [!WARNING]
> Detection results may not always be accurate. AIâ€‘generated content detection is an evolving field â€” always verify with additional methods when necessary.

## âœ¨ Features

| Module | Capabilities |
|--------|-------------|
| ğŸ–¼ï¸ **Image Detection** | CLIP & ViT model classification, noise analysis, texture analysis, Fourier Transform pattern detection, metadata inspection, invisible watermark detection |
| ğŸ¬ **Video Detection** | Frameâ€‘byâ€‘frame analysis using the same image detection pipeline |
| ğŸµ **Audio Deepfake Detection** | Spectral feature extraction (MFCCs, spectral centroid, chroma, ZCR) with a RandomForest classifier |
| ğŸŒ **Gradio Web UI** | Tabbed interface for image and audio detection â€” upload & analyze in your browser |
| âŒ¨ï¸ **CLI** | Scriptable commandâ€‘line interface for quick or batch processing |

---

## ğŸ“‹ Prerequisites

| Requirement | Details |
|-------------|---------|
| **Python** | `>= 3.11` |
| **PyTorch** | `>= 2.5` (CUDAâ€‘enabled GPU recommended for faster inference) |
| **OS** | Windows / Linux / macOS |

---

## ğŸš€ Installation

### 1. Clone the repository

```bash
git clone https://github.com/iamsrishanth/AI-Detector.git
cd AI-Detector
```

### 2. Create a virtual environment *(recommended)*

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux / macOS
source venv/bin/activate
```

### 3. Install dependencies

**Using pip:**

```bash
pip install -e .
```

**Using uv (fast Python package manager):**

```bash
uv sync
```

**Using requirements.txt:**

```bash
pip install -r requirements.txt
```

> [!TIP]
> If you have an NVIDIA GPU, ensure you install the CUDAâ€‘enabled version of PyTorch for significantly faster inference. Visit [pytorch.org/get-started](https://pytorch.org/get-started/locally/) for platform-specific instructions.

---

## ğŸ¯ Usage

### Commandâ€‘Line Interface (CLI)

```bash
# Analyze an image
ai-detect --image path/to/image.jpg

# Analyze a video
ai-detect --video path/to/video.mp4

# Analyze an audio file
ai-detect --audio path/to/audio.wav

# Launch the Gradio web interface
ai-detect --gui
```

### Python API

```python
from ai_detector.image import ImageDetector
from ai_detector.audio import AudioProcessor, DeepfakeDetector

# â”€â”€ Image / Video Detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
detector = ImageDetector()
detector.load_models()
result = detector.process_image("photo.jpg")       # single image
result = detector.process_video("clip.mp4")         # video

# â”€â”€ Audio Deepfake Detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
processor = AudioProcessor()
det = DeepfakeDetector()
det.load_model()

features  = processor.extract_features("audio.wav")
result    = det.predict(features)

print(f"Deepfake probability: {result['deepfake_probability'] * 100:.1f}%")
```

### Gradio Web UI

Launch the web interface and open it in your browser:

```bash
ai-detect --gui
```

The UI provides a tabbed interface with separate tabs for **Image Detection** and **Audio Detection** â€” simply upload a file and click **Analyze**.

---

## ğŸ“‚ Project Structure

```
AI-Detector/
â”œâ”€â”€ ai_detector/
â”‚   â”œâ”€â”€ __init__.py               # Package init
â”‚   â”œâ”€â”€ app.py                    # Gradio web interface
â”‚   â”œâ”€â”€ cli.py                    # CLI entry point
â”‚   â”œâ”€â”€ image/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ detector.py           # Image & video detection (CLIP + ViT)
â”‚   â””â”€â”€ audio/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py             # Audio detection settings
â”‚       â”œâ”€â”€ models.py             # Pydantic response models
â”‚       â”œâ”€â”€ processor.py          # Audio feature extraction
â”‚       â””â”€â”€ detector.py           # Deepfake detection (RandomForest)
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_image_detector.py
â”‚   â”œâ”€â”€ test_audio_detector.py
â”‚   â””â”€â”€ test_audio_processor.py
â”œâ”€â”€ pyproject.toml                # Project metadata & dependencies
â”œâ”€â”€ requirements.txt              # Pip requirements
â”œâ”€â”€ LICENSE                       # Apache License 2.0
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Tech Stack

<table>
  <tr>
    <td align="center"><b>Deep Learning</b></td>
    <td>PyTorch Â· Transformers (HuggingFace) Â· CLIP Â· ViT</td>
  </tr>
  <tr>
    <td align="center"><b>Audio Analysis</b></td>
    <td>Librosa Â· SoundFile Â· SciPy</td>
  </tr>
  <tr>
    <td align="center"><b>ML</b></td>
    <td>scikitâ€‘learn (RandomForest)</td>
  </tr>
  <tr>
    <td align="center"><b>Computer Vision</b></td>
    <td>OpenCV Â· Pillow</td>
  </tr>
  <tr>
    <td align="center"><b>Web UI</b></td>
    <td>Gradio</td>
  </tr>
  <tr>
    <td align="center"><b>Data Validation</b></td>
    <td>Pydantic</td>
  </tr>
</table>

---

## ğŸ§ª Running Tests

```bash
# Using pytest
pytest

# Verbose output
pytest -v
```

---

## ğŸ¤ Contributing

Contributions are welcome! Feel free to open an issue or submit a pull request.

1. **Fork** the repository
2. **Create** a feature branch â€” `git checkout -b feature/amazing-feature`
3. **Commit** your changes â€” `git commit -m "Add amazing feature"`
4. **Push** to your branch â€” `git push origin feature/amazing-feature`
5. **Open** a Pull Request

---

## ğŸ“„ License

This project is licensed under the **Apache License 2.0** â€” see the [LICENSE](LICENSE) file for details.

---

<div align="center">
  <sub>Built with â¤ï¸ by <a href="https://github.com/iamsrishanth">iamsrishanth</a></sub>
</div>
